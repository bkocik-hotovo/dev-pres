<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>RAG</title>
    <link rel="stylesheet" href="https://unpkg.com/reveal.js/dist/reveal.css">
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="dist/font">
    <style>
        @font-face {
            font-family: 'GT Walsheim Pro';
            src: url('font/GT-Walsheim-Light.woff2') format('woff2'),
            url('font/GT-Walsheim-Light.woff') format('woff'),
            url('font/GT-Walsheim-Light.ttf') format('truetype'),
            url('font/GT-Walsheim-Light.eot') format('embedded-opentype');
            font-weight: 300;
            font-style: normal;
        }

        @font-face {
            font-family: 'GT Walsheim Pro';
            src: url('font/GT-Walsheim-Bold.woff2') format('woff2'),
            url('font/GT-Walsheim-Bold.woff') format('woff'),
            url('font/GT-Walsheim-Bold.ttf') format('truetype'),
            url('font/GT-Walsheim-Bold.eot') format('embedded-opentype');
            font-weight: 700;
            font-style: normal;
        }

        @font-face {
            font-family: 'GT Walsheim Pro';
            src: url('font/GT-Walsheim-Bold-Oblique.woff2') format('woff2'),
            url('font/GT-Walsheim-Bold-Oblique.woff') format('woff'),
            url('font/GT-Walsheim-Bold-Oblique.ttf') format('truetype');
            font-weight: 700;
            font-style: oblique;
        }
        body, .reveal p, .reveal ul, .reveal li, .reveal div, .reveal span, .reveal h3 .reveal h1 .reveal div {
            font-family: 'GT Walsheim Pro', sans-serif !important;
        }
        h3 {
            font-size: 1.5em;
        }

        .reveal .slides {
            width: 64% !important;
            height: auto;
            transform: translate(-50%, -50%) scale(1);
        }
    </style>
</head>

<body>

<div class="reveal">
    <div class="slides">

        <section data-background-color="#141914" class="t-center">
            <img src="dist/image.png" alt="Static Image"
                 style="position: absolute; top: 350px; left: 20px; width: 320px; z-index: -1;">

            <h1 class="t-yellow">RAG</h1>
            <h3 class="t-gray">Retrieval-Augmented Generation</h3>
        </section>


        <section>
            <h3 class="t-yellow">Zopár základných pojmov</h3>
            <ul>
                <li><strong>Chunk:</strong> menšia časť textu pre ľahšie vyhľadávanie relevantných dát</li>
                <li><strong>Query/User Prompt:</strong> otázka, ktorú zadáva používateľ modelu</li>
                <li><strong>System Prompt:</strong> upravuje správanie modelu</li>
                <li><strong>Embedding:</strong> numerická reprezentácia chunku na porovnávanie sémantickej podobnosti</li>
                <li><strong>Token:</strong> základná jednotka textu spracovaná modelom</li>
                <li><strong>LLM Context Window:</strong> maximálny počet tokenov, ktoré vie model držať v svojej pamäti </li>
            </ul>
        </section>

        <section>
            <h3 class="t-yellow">Čo je RAG?</h3>
            <ul>
                <li>Pri retrievale získava najvhodnejšie informácie z externých zdrojov mimo modelu</li>
                <li>Používa tieto informácie ako kontext pre generatívne modely</li>
                <li>Generuje odpovede na základe aktuálne dostupného kontextu a otázky používateľa</li>
            </ul>
        </section>



        <section>
            <h3 class="t-yellow">Spracovanie dát</h3>
            <ul>
                <li>Knižnice na spracovanie dokumentov
                    <ul>
                        <li><strong>Unstructured/PyMuPDF:</strong> na extrakciu textu a obrázkov</li>
                        <li><strong>Camelot:</strong> pre extrakciu údajov z tabuliek</li>
                    </ul>
                </li>
                <li>Rozdelenie na chunky
                    <ul>
                        <li>podľa regexu</li>
                        <li>sémanticky pomocou LangChain</li>
                    </ul>
                </li>
                <li>Vektorové databázy
                    <ul>
                        <li>PGVector</li>
                        <li>Chroma</li>
                        <li>Pinecone</li>
                    </ul>
                </li>
            </ul>
        </section>


        <section>
            <h3 class="t-yellow">Jednoduchý workflow RAG</h3>
            <img src="dist/naive-300.png" alt="Jednoduchý RAG workflow" style="max-width: 100%; height: auto;">
        </section>

        <section>
            <h3 class="t-yellow">Code snippet</h3>
            <pre><code class="python">
<span style="color: #569CD6">elements</span> = <span style="color: #DCDCAA">partition_pdf</span>(<span style="color: #CE9178">"example.pdf"</span>)

<span style="color: #6A9955"># Extract text content</span>
<span style="color: #569CD6">doc_content</span> = <span style="color: #CE9178">' '</span>.join(<span style="color: #569CD6">element.page_content</span>
                <span style="color: #569CD6">for</span> <span style="color: #569CD6">element</span> <span style="color: #569CD6">in</span> <span style="color: #569CD6">elements</span> <span style="color: #569CD6">if</span> <span style="color: #569CD6">element.page_content</span>)

<span style="color: #6A9955"># Semantic chunking and embedding</span>
<span style="color: #569CD6">text_splitter</span> = <span style="color: #DCDCAA">SemanticChunker</span>(<span style="color: #DCDCAA">OpenAIEmbeddings</span>())
<span style="color: #569CD6">chunks</span> = <span style="color: #569CD6">text_splitter.split_text</span>(<span style="color: #569CD6">doc_content</span>)
<span style="color: #569CD6">embeddings</span> = <span style="color: #569CD6">text_splitter.embeddings.embed_documents</span>(<span style="color: #569CD6">chunks</span>)

<span style="color: #6A9955"># Insert chunks and embeddings into `pgvector` table</span>

<span style="color: #6A9955"># Retrieve 5 similar chunks by cosine similarity</span>
<span style="color: #569CD6">def</span> <span style="color: #DCDCAA">retrieve_similar_chunks</span>(<span style="color: #569CD6">query_embedding</span>, <span style="color: #569CD6">top_k</span>=<span style="color: #569CD6">5</span>):
    <span style="color: #569CD6">cursor.execute</span>(
        <span style="color: #CE9178">"""
        SELECT chunk
        FROM embeddings_table
        ORDER BY embedding <=> %s
        LIMIT %s
        """</span>,
        (<span style="color: #569CD6">query_embedding</span>, <span style="color: #569CD6">top_k</span>)
    )
    <span style="color: #569CD6">return</span> [<span style="color: #569CD6">row</span>[<span style="color: #569CD6">0</span>] <span style="color: #569CD6">for</span> <span style="color: #569CD6">row</span> <span style="color: #569CD6">in</span> <span style="color: #569CD6">cursor.fetchall</span>()]

<span style="color: #6A9955"># Example embedding of query for retrieval</span>
<span style="color: #569CD6">user_prompt</span> = <span style="color: #CE9178">"What is RAG?"</span>
<span style="color: #569CD6">query_embedding</span> = <span style="color: #569CD6">text_splitter.embeddings.embed_query</span>([<span style="color: #569CD6">user_prompt</span>])
<span style="color: #569CD6">retrieved_chunks</span> = <span style="color: #569CD6">retrieve_similar_chunks</span>(<span style="color: #569CD6">query_embedding</span>)

<span style="color: #6A9955"># Define system prompt and LLM</span>
<span style="color: #569CD6">prompt</span> = <span style="color: #DCDCAA">ChatPromptTemplate.from_messages</span>(
    [
        (<span style="color: #CE9178">"system"</span>, <span style="color: #CE9178">"You are a helpful POC assistant that helps summarize
                retrieved content relevant to the user prompt."</span>),
        (<span style="color: #CE9178">"human"</span>, <span style="color: #CE9178">"{retrieved_chunks}"</span>),
        (<span style="color: #CE9178">"human"</span>, <span style="color: #CE9178">"{user_prompt}"</span>)
    ]
)
<span style="color: #569CD6">llm</span> = <span style="color: #DCDCAA">OpenAI</span>()

<span style="color: #6A9955"># Chain prompt and LLM invocation</span>
<span style="color: #569CD6">chain</span> = <span style="color: #569CD6">prompt</span> | <span style="color: #569CD6">llm</span>
<span style="color: #569CD6">response</span> = <span style="color: #569CD6">chain.invoke</span>(
    {
        <span style="color: #CE9178">"retrieved_chunks"</span>: <span style="color: #569CD6">'\n'.join</span>(<span style="color: #569CD6">retrieved_chunks</span>),
        <span style="color: #CE9178">"user_prompt"</span>: <span style="color: #569CD6">user_prompt</span>
    }
)
</code></pre>
            <aside class="notes">
                <ul>
                    <li>Rýchla ukážka jednoduchého RAG workflowu:</li>
                    <li>1. Extrakcia obsahu z PDF pomocou `partition_pdf`.</li>
                    <li>2. Spojenie textových segmentov do jedného reťazca.</li>
                    <li>3. Delenie textu a získanie embeddingov pomocou `SemanticChunker`.</li>
                    <li>4. Uloženie embeddingov do databázy (napr. `pgvector`).</li>
                    <li>5. Získanie relevantných chunkov na základe cosine similarity.</li>
                    <li>6. Použitie LLM na odpoveď s kontextom.</li>
                </ul>
            </aside>

        </section>

        <section>
            <h3 class="t-yellow">Komplexnejší workflow RAG</h3>
            <img src="dist/advanced-300.png" alt="Komplexný RAG workflow" style="max-width: 100%; height: auto;">
        </section>

        <section>
            <h3 class="t-yellow">Komplexnejší workflow RAG</h3>
                <div>
                    <ul>
                        <li><strong>Query Transformation:</strong> LLM rozkladá zložitý dotaz na sub-queries</li>
                        <li><strong>Query Routing:</strong> nasmerovanie dotazu k relevantnému zdroju</li>
                        <li><strong>Hybrid Retrieval:</strong> spojenie semantického vyhľadávania s kľúčovými slovami</li>
                        <li><strong>Chunk Re-ranking:</strong> najrelevantnejšie chunky sú prioritizované</li>
                        <li><strong>Summary Index:</strong> rýchle vyhľadávanie v sumároch dokumentov</li>
                    </ul>
                </div>
        </section>

        <section>
            <h3 class="t-yellow">Nastavenie system promptu</h3>
            <ul>
                <li><strong>Vymedzenie dát pre odpovede:</strong> model odpovedá iba na základe poskytnutých kontextových údajov, s rozlíšením medzi poskytnutými chunkmi a jeho vlastnými poznatkami</li>
                <li><strong>Špecifikácia vstupu a výstupu:</strong> presné definovanie, ako model spracuje dotaz, vrátane štruktúry user query a relevantných chunkov, aby nedošlo k nesprávnemu vyloženiu query</li>
                <li><strong>Štandardizovaný výstup:</strong> je dôležité presne nastaviť formát očakávaného výstupu pre konzistentné výsledky</li>
            </ul>
        </section>

        <section>
            <h3 class="t-yellow">Use cases a limitácie</h3>
            <ul>
                <li><strong>Praktické použitia:</strong> ideálne pre prostredia, kde sa často vyhľadávajú informácie v dokumentoch – efektívne pri statických dátach, kde môžu byť vopred pripravené prompty</li>
                <li><strong>Obmedzenia úložiska:</strong> veľkosť jedného 1536 dimenzionalneho vektoru je približne 6 KB, čo zvyšuje náročnosť na úložisko</li>
                <li><strong>Výber embedding modelu:</strong> správny embedding model je kľúčový, keďže modely sa špecializujú na rôzne prípady použitia</li>
                <li><strong>Prompt engineering:</strong> efektivitu môže znížiť nedostatočná znalosť používateľa v správnom formulovaní dotazov</li>
            </ul>
          </section>

        <section>
            <h2 class="t-yellow">Ďakujem za pozornosť</h2>
        </section>
    </div>
</div>

<script src="https://unpkg.com/reveal.js/dist/reveal.js"></script>
<script src="plugin/notes/notes.js"></script>
<script>
    Reveal.initialize({
        plugins: [RevealNotes],
    });
</script>
</body>
</html>